using HDF5
using Dates
using Statistics
using DelimitedFiles

include("generator_functions_lininterp.jl")

# x and y arrays remain the same at each time step

# Choose the time bounds of interest using the next two lines
# DateTime(Year,Month,Day,Hour,Minute,Second) [24 Hour Format]
start_date = DateTime(2003, 7, 26, 0, 0, 0)
end_date = DateTime(2003, 8, 6, 0, 0, 0)
time_step = Hour(6) # time step in hours (must be a multiple of 6)

date_range = start_date:time_step:end_date
num_time_steps = length(date_range)

# conversion factor from degrees to metres:  mean circumference of Earth at the equator is 12756000m and there are 2Ï€ radians in a circle, so to obtain metres from degrees at the equator we multiply by 12756000/2Ï€
# I sent the incorrect circumference...please check what I send.
# Correct circumference of Earth is 40,075 km. The diameter of Earth is 12,756 km. (Change this in the function file too.)
deg2metr = 40075000/360 
# length_one_long = 111320
# length_one_lat = 111200

# conversion factor from days to seconds
# why needed?
# For computation of a, we feed in Ì„v (metres per second), L_max and â„“ (metres) to the formula, so Ï„ should be in seconds for consistent units.
# day2secs = 86400

# Before we begin, we calculate a suitable value of Ïµ for the generator
# calculations below, using a mean of the norm of the wind velocity vectors
# from our data set over the time interval of choice over all space and time.

# set up lon,lat grid objects now for a smaller domain
# lonmin, lonmax, latmin and latmax must all be contained within the original data domain bounds
# The above parameters are used to reduce the size of the longitude and latitude range vectors.
# Î´_x/0.25 and Î´_y/0.25 must both be whole numbers and factors of 4*(lonmax-lonmin) and 4*(latmax-latmin) respectively.

println("Setting up the grid...")

lonmin, lonspacing, lonmax = 15, 1, 60
latmin, latspacing, latmax = 30, 1, 75

d, grid = make_dict_grid(lonmin, lonmax, lonspacing, latmin, latmax, latspacing)

println("Calculating a suitable value for Ïµ...")

#we should not just rename variables.  this makes it harder to search for the same object in the file
# I've renamed the variables to better match the notation in Overleaf.
centres = grid.centres

â„“ = [zeros(length(centres)) ; (grid.latspacing)*(deg2metr)*ones(length(centres))]

for c âˆˆ 1:length(centres)
    â„“[c] = grid.lonspacing * cosd(centres[c][2]) * deg2metr
end

â„“_median = median(â„“) # This is supposed to read \bar{\ell}, writing \bar then \ell throws a parsing error.
println("The calculated â„“_median is... $â„“_median")
# â„“_median values: East 103558.27907017531
# 103617.76195096408

#do not hard code values without explanation.
#ideally call these some descriptive variable names with comment.

# Calculate median of the speeds within ğ•„
# Read in longitude and latitude data from our velocity files, and use these to find appropriate index ranges pertaining to the spatial extent of ğ•„.

name_of_file = "ERA5_atmos_6Hourly_Summer2003/ERA5_atmos_6HR_" * string(year(start_date)) * lpad(month(start_date), 2, "0") * lpad(day(start_date), 2, "0") * "_" * lpad(hour(start_date), 2, "0") * "00.h5"
file_ID = h5open(name_of_file)

M_lons = read(file_ID, "/longitude")
M_lats = read(file_ID, "/latitude")
M_lats = reverse(M_lats)

M_lons_index_range = findall(x->(x>=lonmin)&&(x<=lonmax),M_lons)
M_lats_index_range = findall(x->(x>=latmin)&&(x<=latmax),M_lats)

close(file_ID)

# This 3D array stores the observed velocity data over all available spatial and temporal data points within ğ•„
speeds_over_ğ•„ = zeros(length(M_lons_index_range)*length(M_lats_index_range),length(date_range))

for Ï„ âˆˆ 1:length(date_range)

    name_of_file = "ERA5_atmos_6Hourly_Summer2003/ERA5_atmos_6HR_" * string(year(date_range[Ï„])) * lpad(month(date_range[Ï„]), 2, "0") * lpad(day(date_range[Ï„]), 2, "0") * "_" * lpad(hour(date_range[Ï„]), 2, "0") * "00.h5"
    file_ID = h5open(name_of_file)

    u_data = read(file_ID, "/ucomp")
    u_data = reverse(u_data, dims=2)

    v_data = read(file_ID, "/vcomp")
    v_data = reverse(v_data, dims=2)

    #do not hard code values without explanation.
    #ideally call these some descriptive variable names with comment.
    
    # speeds_now contains all of the wind speeds calculated for this particular time instance...
    speeds_now = sqrt.(u_data[M_lons_index_range,M_lats_index_range].^2 .+ v_data[M_lons_index_range,M_lats_index_range].^2)
    
    # ... which are then fed into the full array used to compute the median.
    global speeds_over_ğ•„[:,Ï„] = speeds_now[:]
    
    close(file_ID)

end

vÌ„ = median(speeds_over_ğ•„)
println("The median of the speeds is... $vÌ„")
# vel_median values: East 9.83595694796086
Ïµ = sqrt(0.1*vÌ„*â„“_median)
println("The calculated Ïµ value is... $Ïµ")
# Ïµ values: East 319.1543160508973
# 319.2459624793616

#=
println("Calculating a suitable value for Ïµ...")

Ïµ = 0

for curr_date âˆˆ date_range

    name_of_file = "ERA5_atmos_6Hourly_Summer2003/ERA5_atmos_6HR_" * string(year(curr_date)) * lpad(month(curr_date), 2, "0") * lpad(day(curr_date), 2, "0") * "_" * lpad(hour(curr_date), 2, "0") * "00.h5"
    file_ID = h5open(name_of_file)

    u_now = read(file_ID, "/ucomp")
    v_now = read(file_ID, "/vcomp")

    vel_norms = sqrt.(u_now.^2 + v_now.^2)
    #vel_norms_m = mean(vel_norms[:]) # m can stand for mean or median
    vel_norms_m = median(vel_norms[:])

    global Ïµ = Ïµ + (vel_norms_m/num_time_steps)

    close(file_ID)

end

Ïµ = 0.05*Ïµ
println("The calculated Ïµ value is... $Ïµ")
=#

Gvec = []

@showprogress for datetime_now âˆˆ date_range

    println("Reading data...")

    name_of_file = "ERA5_atmos_6Hourly_Summer2003/ERA5_atmos_6HR_" * string(year(datetime_now)) * lpad(month(datetime_now), 2, "0") * lpad(day(datetime_now), 2, "0") * "_" * lpad(hour(datetime_now), 2, "0") * "00.h5"
    file_ID = h5open(name_of_file)

    @time begin

        # lons_data and lats_data are vectors containing the ranges of longitudinal 
        # and latitudinal coordinates (respectively) used to produce the grid over 
        # which the wind velocity data is defined.

        # lons_data is given in units of degrees longitude East (negative indicates
        # degrees longitude West), while lats_data is given in units of degrees 
        # latitude North (South if negative, we won't be dealing with this case yet).

        lons_data = read(file_ID, "/longitude")
        lats_data = read(file_ID, "/latitude")

        # u_data and v_data are the zonal and meridional components (respectively)
        # of the wind velocity vector data defined over the grid constructured using
        # lons_data and lats_data. They are each given in units of metres per second. 

        u_data = read(file_ID, "/ucomp")
        v_data = read(file_ID, "/vcomp")

        #u_data = -u_data
        #v_data = -v_data

    end

    println("Creating interpolant...")

    @time Iplt_zonal, Iplt_meridional = get_linear_interpolant(lons_data, lats_data, u_data, v_data)
    F(x) = [(1).*Iplt_zonal(x[1], x[2]), (1).*Iplt_meridional(x[1], x[2])]

    println("Creating generator...")

    @time G = make_generator(d, grid, F, Ïµ)

    push!(Gvec, G)

    if datetime_now == start_date
        Î»_now, v_now = eigs(G, which=:LR, nev=10, maxiter=100000)
        println(collect(Î»_now))
    end

    close(file_ID)

end

#what are you doing here?  what are these other factors?  There should be no need, or let me know if you think there is a need.
L_max_lon = (grid.lonmax - grid.lonmin)*cosd(grid.latmin)*deg2metr
L_max_lat = (grid.latmax - grid.latmin)*deg2metr
a = ((end_date-start_date)/Day(1))*sqrt(1.1*vÌ„*â„“_median)/(max(L_max_lon,L_max_lat)) # East: 0.0023268717590320966
println("The heuristic for a is... $a")
# a: 0.0023250425067356953

a = 0.0032

println("Making inflated generator...")
@time ğ† = make_inflated_generator(Gvec, time_step, a)

println("Computing inflated eigenvalues...")
@time Î›, V = eigs(ğ†, which=:LR, nev=20, maxiter=100000)
println(collect(Î›))

println("Plotting slices...")
@time plot_slices(Î›, V, grid, 2, a)
@time plot_spatemp_IDL(grid, V)
#@time plot_9vecs_IDL(grid, V, date_range)
#@time plot_9morevecs_IDL(grid, V, date_range)
#@time plot_Nvecs_IDL(grid, V, date_range)
#=
seba_inds = [1 ; 2 ; 4 ; 5 ; 9 ; 10]
Î£, â„› = SEBA(real.(V[:, seba_inds]))
println("The respective SEBA vector minima are ", minimum(Î£, dims=1))
@time plot_SEBA_IDL(grid, Î£, date_range)
#@time make_SEBA_IDL(grid, V, seba_inds, date_range)

time_now = now()
name_save_file = "IDL_Results_EuroBlock_East_3DayExtension_" * string(year(time_now)) * lpad(month(time_now), 2, "0") * lpad(day(time_now), 2, "0") * "_" * lpad(hour(time_now), 2, "0") * lpad(minute(time_now), 2, "0") * ".h5"
@time save_results_IDL(grid, Î›, V, Î£, name_save_file)
=#
